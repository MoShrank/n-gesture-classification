{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "norse-tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "60a8c1ab037049ecbc1b3468766cd12c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1087d199804c4637823934fddc5b7189",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4df71b3f75b549fca553e82c0d4106b2",
              "IPY_MODEL_ac382fbd5a9b4d61ab9fe49f0a8f4d4f",
              "IPY_MODEL_d5a5a4b1fc0a47ed979da739e2c5290f"
            ]
          }
        },
        "1087d199804c4637823934fddc5b7189": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4df71b3f75b549fca553e82c0d4106b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2aaceb090bec474ca000a6e78893b828",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_69895522c37640f394dd6b1c10143821"
          }
        },
        "ac382fbd5a9b4d61ab9fe49f0a8f4d4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3eaceb560ffc440a9a3bf0babc9c1376",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 700096,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 700096,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_51f3596b122c43698eb4470dd8922993"
          }
        },
        "d5a5a4b1fc0a47ed979da739e2c5290f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9be851c9f154420da18c83b604771aa6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 700416/? [00:00&lt;00:00, 1204903.75it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_83004b76a6504d928ea3f0bbeb9e8094"
          }
        },
        "2aaceb090bec474ca000a6e78893b828": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "69895522c37640f394dd6b1c10143821": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3eaceb560ffc440a9a3bf0babc9c1376": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "51f3596b122c43698eb4470dd8922993": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9be851c9f154420da18c83b604771aa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "83004b76a6504d928ea3f0bbeb9e8094": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df1238ddd54a40c998a695cdbd92c479": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6149cdd530df471f924b3e29520fcc07",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_eefd3d4b01df480092d0a6d9ad6f72f6",
              "IPY_MODEL_08ba3550fe0e444097de7d97d21155b7",
              "IPY_MODEL_3ec260061ab84313b7d99c18704d3a6f"
            ]
          }
        },
        "6149cdd530df471f924b3e29520fcc07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eefd3d4b01df480092d0a6d9ad6f72f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_755df560f7dc4c6fa74c56ccc12d9eea",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_569686f961744493bea02bc8841d7867"
          }
        },
        "08ba3550fe0e444097de7d97d21155b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f642ebd62fa8446db7388eda4a27a843",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 311022,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 311022,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9fe9be512b424a04bf4c8d12a1c3e080"
          }
        },
        "3ec260061ab84313b7d99c18704d3a6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_33c66a00795d498ba88cf4369c9261ab",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 311296/? [00:00&lt;00:00, 753993.35it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e512da76c821422393ab88be93373f65"
          }
        },
        "755df560f7dc4c6fa74c56ccc12d9eea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "569686f961744493bea02bc8841d7867": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f642ebd62fa8446db7388eda4a27a843": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9fe9be512b424a04bf4c8d12a1c3e080": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "33c66a00795d498ba88cf4369c9261ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e512da76c821422393ab88be93373f65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7IYU0Bqomb2"
      },
      "source": [
        "# Training a classifier on the event-based POKER-DVS dataset\n",
        "\n",
        "When working with Spiking Neural Networks (SNN), we will inevitably encounter the notion of _time_ in our network and data flow. The classic example of MNIST handwritten digits consists of images, much like snapshots in time. Deep learning has shown impressive results on such purely spatial compositions, but SNNs might be able to extract meaning from temporal features and/or save power doing so in comparison to classical networks. \n",
        "\n",
        "An event camera such as the Dynamic Vision Sensor (DVS) is [somewhat based](https://medium.com/@gregorlenz/rethinking-the-way-our-cameras-see-8584b5167bb) on the functional principle of the human retina. Such a camera can record a scene much more efficiently than a conventional camera by encoding the changes in a visual scene rather than absolute illuminance values. The output is a spike train of change detection events for each pixel. While previously we had to use encoders to equip static image data with a temporal dimension, the POKER-DVS dataset contains recordings of poker cards that are shown to an event camera in rapid succession.\n",
        "\n",
        "**Warning!** This notebook uses a large dataset and can take a significant amount of time to execute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wu93JGgT2CJ2"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rmUJSdzqypr"
      },
      "source": [
        "We can simply install Norse through pip:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPb7tCeX2Jkb",
        "outputId": "497deaa3-d781-4467-878a-9d64b2377390"
      },
      "source": [
        "!pip install norse --quiet"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |███                             | 10 kB 23.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 20 kB 23.8 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 30 kB 19.5 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 40 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 51 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 61 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 71 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 81 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 92 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 102 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 109 kB 5.7 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for norse (PEP 517) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQIzPZLYiaOI"
      },
      "source": [
        "For this tutorial we are going to make use of a package that handles event-based datasets called [Tonic](https://github.com/neuromorphs/tonic). It is based on PyTorch Vision, so you should already have most of its dependencies installed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAr-Ue02iaOI",
        "outputId": "87adca42-c049-4228-f9c0-cd4137ced8c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install tonic --quiet"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |████▍                           | 10 kB 22.4 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 20 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 30 kB 16.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 40 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 51 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 61 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 71 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 74 kB 2.1 MB/s \n",
            "\u001b[?25h  Building wheel for importRosbag (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OU3_PtPBiaOI"
      },
      "source": [
        "Let's start by loading the POKER-DVS dataset and specifying a sparse tensor transform whenever a new sample is loaded"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tHD7Q5apJM1",
        "outputId": "e1485c36-aafa-4835-caeb-9ffd24c3ff44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip freeze | grep 'tonic'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tonic==1.0.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149,
          "referenced_widgets": [
            "60a8c1ab037049ecbc1b3468766cd12c",
            "1087d199804c4637823934fddc5b7189",
            "4df71b3f75b549fca553e82c0d4106b2",
            "ac382fbd5a9b4d61ab9fe49f0a8f4d4f",
            "d5a5a4b1fc0a47ed979da739e2c5290f",
            "2aaceb090bec474ca000a6e78893b828",
            "69895522c37640f394dd6b1c10143821",
            "3eaceb560ffc440a9a3bf0babc9c1376",
            "51f3596b122c43698eb4470dd8922993",
            "9be851c9f154420da18c83b604771aa6",
            "83004b76a6504d928ea3f0bbeb9e8094",
            "df1238ddd54a40c998a695cdbd92c479",
            "6149cdd530df471f924b3e29520fcc07",
            "eefd3d4b01df480092d0a6d9ad6f72f6",
            "08ba3550fe0e444097de7d97d21155b7",
            "3ec260061ab84313b7d99c18704d3a6f",
            "755df560f7dc4c6fa74c56ccc12d9eea",
            "569686f961744493bea02bc8841d7867",
            "f642ebd62fa8446db7388eda4a27a843",
            "9fe9be512b424a04bf4c8d12a1c3e080",
            "33c66a00795d498ba88cf4369c9261ab",
            "e512da76c821422393ab88be93373f65"
          ]
        },
        "id": "ZzPRyc8E2M8a",
        "outputId": "0a0e6af1-f872-4a9c-a940-15059920e5b1"
      },
      "source": [
        "import tonic\n",
        "import torchvision\n",
        "\n",
        "sensor_size = tonic.datasets.POKERDVS.sensor_size\n",
        "frame_transform = tonic.transforms.ToFrame(sensor_size=sensor_size, time_window=1000)\n",
        "\n",
        "trainset = tonic.datasets.POKERDVS(save_to='./data', train=True)\n",
        "testset = tonic.datasets.POKERDVS(save_to='./data', transform=frame_transform, train=False)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.neuromorphic-vision.com/public/downloads/pips_train.tar.gz to ./data/POKERDVS/pips_train.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60a8c1ab037049ecbc1b3468766cd12c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/700096 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/POKERDVS/pips_train.tar.gz to ./data/POKERDVS\n",
            "Downloading https://www.neuromorphic-vision.com/public/downloads/pips_test.tar.gz to ./data/POKERDVS/pips_test.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df1238ddd54a40c998a695cdbd92c479",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/311022 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/POKERDVS/pips_test.tar.gz to ./data/POKERDVS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfK3zyFBiaOI"
      },
      "source": [
        "We can have a look at how a sample of one digit looks like. The event camera's output is encoded as events that have x/y coordinates, a timestamp and a polarity that indicates whether the lighting increased or decreased at that event. The events are provided in an (NxE) array. Let's have a look at the first example in the dataset. Every row in the array represents one event of timestamp, x, y, and polarity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKuBSZmuiaOJ"
      },
      "source": [
        "events = trainset[0][0]\n",
        "events"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDhrA-4MiaOJ"
      },
      "source": [
        "When accumulated over time into 3 bins, the images show 1 of 4 card symbols"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwT2om6_iaOJ"
      },
      "source": [
        "tonic.utils.plot_event_grid(events)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJv_jc73iaOJ"
      },
      "source": [
        "And this one is the target class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjSGI6PZiaOJ"
      },
      "source": [
        "trainset[0][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5Qc_HM8iaOK"
      },
      "source": [
        "We wrap the training and testing sets in PyTorch DataLoaders that facilitate file loading. Note also the custom collate function __pad_tensors__ , which makes sure that all sparse tensors in the batch have the same dimensions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPs81D-QrFWV"
      },
      "source": [
        "# reduce this number if you run out of GPU memory\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# add sparse transform to trainset, previously omitted because we wanted to look at raw events\n",
        "trainset.transform = frame_transform\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(trainset,\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        collate_fn=tonic.collation.PadTensors(batch_first=False),\n",
        "                                        shuffle=True\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(testset,\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        collate_fn=tonic.collation.PadTensors(batch_first=False),\n",
        "                                        shuffle=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNEqcSNH2WfP"
      },
      "source": [
        "## Defining a Network\n",
        "\n",
        "Once the data is encoded into spikes, a spiking neural network can be constructed in the same way as a one would construct a recurrent neural network.\n",
        "Here we define a spiking neural network with one recurrently connected layer\n",
        "with `hidden_features` LIF neurons and a readout layer with `output_features` and leaky-integrators. As you can see, we can freely combine spiking neural network primitives with ordinary `torch.nn.Module` layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qN9Sm4rJtgc7"
      },
      "source": [
        "from norse.torch import LIFParameters, LIFState\n",
        "from norse.torch.module.lif import LIFCell, LIFRecurrentCell\n",
        "# Notice the difference between \"LIF\" (leaky integrate-and-fire) and \"LI\" (leaky integrator)\n",
        "from norse.torch import LICell, LIState\n",
        "\n",
        "from typing import NamedTuple\n",
        "\n",
        "class SNNState(NamedTuple):\n",
        "    lif0 : LIFState\n",
        "    readout : LIState\n",
        "\n",
        "\n",
        "class SNN(torch.nn.Module):\n",
        "    def __init__(self, input_features, hidden_features, output_features, tau_syn_inv, tau_mem_inv, record=False, dt=1e-3):\n",
        "        super(SNN, self).__init__()\n",
        "        self.l1 = LIFRecurrentCell(\n",
        "            input_features,\n",
        "            hidden_features,\n",
        "            p=LIFParameters(alpha=100, \n",
        "                            v_th=torch.as_tensor(0.3),\n",
        "                            tau_syn_inv=tau_syn_inv,\n",
        "                            tau_mem_inv=tau_mem_inv,\n",
        "                           ),\n",
        "            dt=dt                     \n",
        "        )\n",
        "        self.input_features = input_features\n",
        "        self.fc_out = torch.nn.Linear(hidden_features, output_features, bias=False)\n",
        "        self.out = LICell(dt=dt)\n",
        "\n",
        "        self.hidden_features = hidden_features\n",
        "        self.output_features = output_features\n",
        "        self.record = record\n",
        "\n",
        "    def forward(self, x):\n",
        "        seq_length, batch_size, _, _, _ = x.shape\n",
        "        s1 = so = None\n",
        "        voltages = []\n",
        "\n",
        "        if self.record:\n",
        "            self.recording = SNNState(\n",
        "              LIFState(\n",
        "                z = torch.zeros(seq_length, batch_size, self.hidden_features),\n",
        "                v = torch.zeros(seq_length, batch_size, self.hidden_features),\n",
        "                i = torch.zeros(seq_length, batch_size, self.hidden_features)\n",
        "              ),\n",
        "              LIState(\n",
        "                v = torch.zeros(seq_length, batch_size, self.output_features),\n",
        "                i = torch.zeros(seq_length, batch_size, self.output_features)\n",
        "              )\n",
        "            )\n",
        "\n",
        "        for ts in range(seq_length):\n",
        "            z = x[ts, :, :, :].view(-1, self.input_features)\n",
        "            z, s1 = self.l1(z, s1)\n",
        "            z = self.fc_out(z)\n",
        "            vo, so = self.out(z, so)\n",
        "            if self.record:\n",
        "                self.recording.lif0.z[ts,:] = s1.z\n",
        "                self.recording.lif0.v[ts,:] = s1.v\n",
        "                self.recording.lif0.i[ts,:] = s1.i\n",
        "                self.recording.readout.v[ts,:] = so.v\n",
        "                self.recording.readout.i[ts,:] = so.i\n",
        "            voltages += [vo]\n",
        "\n",
        "        return torch.stack(voltages)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHYv70KHiaOL"
      },
      "source": [
        "It's a good idea to test the network's response to time constant parameters that depend on the duration of recordings in the dataset as well as average number of events. We use dt=1e-6 because the events we're dealing with have microsecond resolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FAUIKZNiaOL"
      },
      "source": [
        "example_snn = SNN(np.product(trainset.sensor_size), 100, len(trainset.classes), tau_syn_inv=torch.tensor(1/1e-2), tau_mem_inv=torch.tensor(1/1e-2), record=True, dt=1e-3)\n",
        "\n",
        "frames, target = next(iter(train_loader))\n",
        "\n",
        "frames[:,:1].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoJbFBdgiaOL"
      },
      "source": [
        "Note that we are only applying a subset (`1000`) of the data timesteps (`22227`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bxo0O1HfiaOL"
      },
      "source": [
        "example_readout_voltages = example_snn(frames[:,:1])\n",
        "voltages = example_readout_voltages.squeeze(1).detach().numpy()\n",
        "\n",
        "plt.plot(voltages)\n",
        "plt.ylabel('Voltage [a.u.]')\n",
        "plt.xlabel('Time [us]')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MT2kUOuSiaOL"
      },
      "source": [
        "plt.plot(example_snn.recording.lif0.v.squeeze(1).detach().numpy())\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXFSvbqwiaOM"
      },
      "source": [
        "plt.plot(example_snn.recording.lif0.i.squeeze(1).detach().numpy())\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1jcJ7LnrlUi"
      },
      "source": [
        "## Training the Network\n",
        "\n",
        "The final model is then simply the sequential composition of our network and a decoding step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHjvr99xiaOM"
      },
      "source": [
        "def decode(x):\n",
        "    x, _ = torch.max(x, 0)\n",
        "    log_p_y = torch.nn.functional.log_softmax(x, dim=1)\n",
        "    return log_p_y\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, snn, decoder):\n",
        "        super(Model, self).__init__()\n",
        "        self.snn = snn\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.snn(x)\n",
        "        log_p_y = self.decoder(x)\n",
        "        return log_p_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4QeDXL9_qaB"
      },
      "source": [
        "LR = 0.002\n",
        "INPUT_FEATURES = np.product(trainset.sensor_size)\n",
        "HIDDEN_FEATURES = 100\n",
        "OUTPUT_FEATURES = len(trainset.classes)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = torch.device(\"cuda\")\n",
        "else:\n",
        "    DEVICE = torch.device(\"cpu\")\n",
        "\n",
        "model = Model(\n",
        "    snn=SNN(\n",
        "      input_features=INPUT_FEATURES,\n",
        "      hidden_features=HIDDEN_FEATURES,\n",
        "      output_features=OUTPUT_FEATURES,\n",
        "      tau_syn_inv=torch.tensor(1/1e-2), \n",
        "      tau_mem_inv=torch.tensor(1/1e-2)\n",
        "    ),\n",
        "    decoder=decode\n",
        ").to(DEVICE)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rM5btRjKdEEv"
      },
      "source": [
        "What remains to do is to setup training and test code. This code is completely independent of the fact that we are training a spiking neural network and in fact has been largely copied from the pytorch tutorials."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXgntmL_rvHO"
      },
      "source": [
        "from tqdm.notebook import tqdm, trange\n",
        "\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    losses = []\n",
        "\n",
        "    for (data, target) in tqdm(train_loader, leave=False):\n",
        "        data, target = data.to(device), torch.LongTensor(target).to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = torch.nn.functional.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "\n",
        "    mean_loss = np.mean(losses)\n",
        "    return losses, mean_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtdcQi_18Xip"
      },
      "source": [
        "Just like the training function, the test function is standard boilerplate, common with any other supervised learning task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gca4ZzatApWD"
      },
      "source": [
        "def test(model, device, test_loader, epoch):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), torch.LongTensor(target).to(device)\n",
        "            output = model(data)\n",
        "            test_loss += torch.nn.functional.nll_loss(\n",
        "                output, target, reduction=\"sum\"\n",
        "            ).item()  # sum up batch loss\n",
        "            pred = output.argmax(\n",
        "                dim=1, keepdim=True\n",
        "            )  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    accuracy = 100.0 * correct / len(test_loader.dataset)\n",
        "\n",
        "    return test_loss, accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wU-b7Q8eBVca"
      },
      "source": [
        "training_losses = []\n",
        "mean_losses = []\n",
        "test_losses = []\n",
        "accuracies = []\n",
        "\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "EPOCHS  = 10\n",
        "\n",
        "for epoch in trange(EPOCHS):\n",
        "    training_loss, mean_loss = train(model, DEVICE, train_loader, optimizer, epoch)\n",
        "    test_loss, accuracy = test(model, DEVICE, test_loader, epoch)\n",
        "    training_losses += training_loss\n",
        "    mean_losses.append(mean_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "print(f\"final accuracy: {accuracies[-1]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKEVGF76x_Ee"
      },
      "source": [
        "We can visualize the output of the trained network on an example input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NL_rtLC2xXLp"
      },
      "source": [
        "trained_snn = model.snn\n",
        "trained_readout_voltages = trained_snn(frames[:,:1].to(\"cuda\"))\n",
        "plt.plot(trained_readout_voltages.squeeze(1).cpu().detach().numpy())\n",
        "\n",
        "plt.ylabel('Voltage [a.u.]')\n",
        "plt.xlabel('Time [ms]')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBBQ98RNiaOT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}